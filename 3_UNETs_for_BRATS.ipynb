{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanBandara/FYP/blob/main/3_UNETs_for_BRATS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0J3wcS2ZQoE"
      },
      "outputs": [],
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.utils import normalize\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gHXJIBCgZprO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14d7c3a-58be-405c-8455-c4571e20e5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the data generator"
      ],
      "metadata": {
        "id": "8GaSfIG6WmeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):\n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            image = np.load(img_dir+image_name)\n",
        "            # print(\"Image - \",image.shape)\n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "\n",
        "    return(images)\n",
        "\n",
        "def load_msk(img_dir, img_list):\n",
        "    images=[]\n",
        "    for i, image_name in enumerate(img_list):\n",
        "        if (image_name.split('.')[1] == 'npy'):\n",
        "            image = np.load(img_dir+image_name)\n",
        "            # print(\"before - \",image.shape)\n",
        "            image = to_categorical(image, num_classes=4)\n",
        "            # print(\"After - \",image.shape)\n",
        "            images.append(image)\n",
        "    images = np.array(images)\n",
        "\n",
        "    return(images)\n",
        "\n",
        "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
        "\n",
        "    L = len(img_list)\n",
        "\n",
        "    #keras needs the generator infinite, so we will use while true\n",
        "    while True:\n",
        "\n",
        "        batch_start = 0\n",
        "        batch_end = batch_size\n",
        "\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "\n",
        "            X = load_img(img_dir, img_list[batch_start:limit])\n",
        "            Y = load_msk(mask_dir, mask_list[batch_start:limit])\n",
        "\n",
        "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples\n",
        "            batch_start += batch_size\n",
        "            batch_end += batch_size"
      ],
      "metadata": {
        "id": "hkfksE-dXGP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Making the data generator"
      ],
      "metadata": {
        "id": "Eo5ycNUKXM1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = \"/content/drive/MyDrive/BRATS_train_data/X_data/\"\n",
        "train_mask_dir = \"/content/drive/MyDrive/BRATS_train_data/Y_data/\"\n",
        "train_img_list=os.listdir(train_img_dir)\n",
        "train_mask_list = os.listdir(train_mask_dir)\n",
        "\n",
        "val_img_dir = \"/content/drive/MyDrive/BRATS_train_data/X_validation/\"\n",
        "val_mask_dir = \"/content/drive/MyDrive/BRATS_train_data/Y_validation/\"\n",
        "val_img_list=os.listdir(val_img_dir)\n",
        "val_mask_list = os.listdir(val_mask_dir)"
      ],
      "metadata": {
        "id": "I9u3OW40YIjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_img_datagen = imageLoader(train_img_dir, train_img_list,\n",
        "                                train_mask_dir, train_mask_list, batch_size)\n",
        "\n",
        "val_img_datagen = imageLoader(val_img_dir, val_img_list,\n",
        "                                val_mask_dir, val_mask_list, batch_size)"
      ],
      "metadata": {
        "id": "wqqnGK6PXMCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Verifying the generator"
      ],
      "metadata": {
        "id": "BO3f9BZXXfGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verify generator.... In python 3 next() is renamed as __next__()\n",
        "img, msk = val_img_datagen.__next__()"
      ],
      "metadata": {
        "id": "gdPUPs1fXc4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing the loaded images"
      ],
      "metadata": {
        "id": "RoY-LQEQZB3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "data_point = random.randint(0, batch_size)\n",
        "# data_point = 3\n",
        "\n",
        "original_labels = np.expand_dims(msk[data_point,:,:,:], axis=0)\n",
        "original_labels = np.argmax(original_labels, axis=3)\n",
        "\n",
        "\n",
        "plt.subplot(341)\n",
        "plt.imshow(img[data_point,:,:,0], cmap='gray')\n",
        "plt.title('Image t1c')\n",
        "plt.subplot(342)\n",
        "plt.imshow(img[data_point,:,:,1], cmap='gray')\n",
        "plt.title('Image t1n')\n",
        "plt.subplot(343)\n",
        "plt.imshow(img[data_point,:,:,2], cmap='gray')\n",
        "plt.title('Image t2f')\n",
        "plt.subplot(344)\n",
        "plt.imshow(img[data_point,:,:,3], cmap='gray')\n",
        "plt.title('Image t2w')\n",
        "plt.subplot(345)\n",
        "plt.imshow(msk[data_point,:,:,0], cmap='gray')\n",
        "plt.title('Label_1')\n",
        "plt.subplot(346)\n",
        "plt.imshow(msk[data_point,:,:,1], cmap='gray')\n",
        "plt.title('Label_2')\n",
        "plt.subplot(347)\n",
        "plt.imshow(msk[data_point,:,:,2], cmap='gray')\n",
        "plt.title('Label_3')\n",
        "plt.subplot(348)\n",
        "plt.imshow(msk[data_point,:,:,3], cmap='gray')\n",
        "plt.title('Label_4')\n",
        "plt.subplot(349)\n",
        "plt.imshow(original_labels.reshape((240,240)))\n",
        "plt.title('Complete label')\n",
        "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "dODfFiTVbJ7j",
        "outputId": "e624dd58-1767-4a1f-e0f3-a586c1d25094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_unet_model():\n",
        "#Build the model\n",
        "    inputs = Input((240, 240, 4))\n",
        "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "f0N3QRBQa6ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining 3 UNET architectures"
      ],
      "metadata": {
        "id": "o0tjF0qzhdsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://youtu.be/L5iV5BHkMzM\n",
        "\"\"\"\n",
        "\n",
        "Attention U-net:\n",
        "https://arxiv.org/pdf/1804.03999.pdf\n",
        "\n",
        "Recurrent residual Unet (R2U-Net) paper\n",
        "https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
        "(Check fig 4.)\n",
        "\n",
        "Note: Batch normalization should be performed over channels after a convolution,\n",
        "In the following code axis is set to 3 as our inputs are of shape\n",
        "[None, height, width, channel]. Channel is axis=3.\n",
        "\n",
        "Original code from below link but heavily modified.\n",
        "https://github.com/MoleImg/Attention_UNet/blob/master/AttResUNet.py\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "A few useful metrics and losses\n",
        "'''\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n",
        "\n",
        "\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "\n",
        "##############################################################\n",
        "'''\n",
        "Useful blocks to build Unet\n",
        "\n",
        "conv - BN - Activation - conv - BN - Activation - Dropout (if enabled)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "def repeat_elem(tensor, rep):\n",
        "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
        "    #by a factor of rep.\n",
        "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n",
        "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
        "\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "    '''\n",
        "    Residual convolutional layer.\n",
        "    Two variants....\n",
        "    Either put activation function before the addition with shortcut\n",
        "    or after the addition (which would be as proposed in the original resNet).\n",
        "\n",
        "    1. conv - BN - Activation - conv - BN - Activation\n",
        "                                          - shortcut  - BN - shortcut+BN\n",
        "\n",
        "    2. conv - BN - Activation - conv - BN\n",
        "                                     - shortcut  - BN - shortcut+BN - Activation\n",
        "\n",
        "    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
        "    '''\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation('relu')(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = layers.add([shortcut, conv])\n",
        "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
        "    return res_path\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    \"\"\"\n",
        "    resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    using 1x1 conv\n",
        "    :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    UNet,\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, conv_16], axis=3)\n",
        "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, conv_32], axis=3)\n",
        "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, conv_64], axis=3)\n",
        "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, conv_128], axis=3)\n",
        "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model\n",
        "    model = models.Model(inputs, conv_final, name=\"UNet\")\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def Attention_UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Attention UNet,\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
        "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
        "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
        "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
        "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"Attention_UNet\")\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def Attention_ResUNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Rsidual UNet, with attention\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "    # input data\n",
        "    # dimension of the image depth\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "    axis = 3\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, double residual convolution + pooling\n",
        "    conv_128 = res_conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = res_conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = res_conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = res_conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = res_conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=axis)\n",
        "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=axis)\n",
        "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=axis)\n",
        "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=axis)\n",
        "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=axis)(conv_final)\n",
        "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model = models.Model(inputs, conv_final, name=\"AttentionResUNet\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "XQwDicNzhick"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_shape = (240,240,4)\n",
        "# # UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)\n",
        "# # Attention_UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)\n",
        "# Attention_ResUNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)"
      ],
      "metadata": {
        "id": "en-rIizgiZZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################\n",
        "# from sklearn.utils import class_weight\n",
        "# class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                  np.unique(train_masks_reshaped_encoded),\n",
        "#                                                  train_masks_reshaped_encoded)\n",
        "# print(\"Class weights are...:\", class_weights)"
      ],
      "metadata": {
        "id": "NH-O4iCbjhcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining loss functions"
      ],
      "metadata": {
        "id": "B7zpyoBZT3CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def jacard_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
        "\n",
        "\n",
        "def jacard_coef_loss(y_true, y_pred):\n",
        "    return -jacard_coef(y_true, y_pred)  # -1 ultiplied as we want to minimize this value as loss function\n",
        "\n",
        "# # Typical tf.keras API usage\n",
        "# import tensorflow as tf\n",
        "# from focal_loss import BinaryFocalLoss,SparseCategoricalFocalLoss"
      ],
      "metadata": {
        "id": "HNG05jfhT2BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import segmentation_models_3D as sm\n",
        "# dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))\n",
        "# focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "# total_loss = dice_loss + (1 * focal_loss)"
      ],
      "metadata": {
        "id": "94qTpaQoUDgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class FocalLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self, alpha=0.25, gamma=2.0):\n",
        "    super(FocalLoss, self).__init__()\n",
        "    self.alpha = alpha\n",
        "    self.gamma = gamma\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Inputs and targets should be of shape (batch_size, num_classes, height, width)\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the cross-entropy loss\n",
        "    ce_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "\n",
        "    # Calculate the scaling factor\n",
        "    pt = tf.math.exp(-ce_loss)\n",
        "    scaling_factor = self.alpha * (1 - pt) ** self.gamma\n",
        "\n",
        "    # Calculate the Focal loss\n",
        "    focal_loss = scaling_factor * ce_loss\n",
        "\n",
        "    # Return the average Focal loss over the batch\n",
        "    return tf.reduce_mean(focal_loss)\n"
      ],
      "metadata": {
        "id": "X4Y1Ji2hVWl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a callback"
      ],
      "metadata": {
        "id": "eqpXKkoHNeNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"/content/drive/MyDrive/models/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Calculate the number of batches per epoch\n",
        "import math\n",
        "n_batches = 1051 / batch_size\n",
        "n_batches = math.ceil(n_batches)    # round up the number of batches to the nearest whole integer\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=10*n_batches)\n"
      ],
      "metadata": {
        "id": "lEA_6NadLL2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 240\n",
        "IMG_WIDTH  =  240\n",
        "IMG_CHANNELS = 4\n",
        "\n",
        "\n",
        "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "# UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)\n",
        "# Attention_UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)\n",
        "# Attention_ResUNet(input_shape, NUM_CLASSES=4, dropout_rate=0.0, batch_norm=True)\n",
        "\n",
        "#loading the model\n",
        "def get_model():\n",
        "    return multi_unet_model()\n",
        "\n",
        "model = UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.4, batch_norm=True)\n",
        "model.compile(optimizer='adam', loss= FocalLoss(), metrics=[jacard_coef])\n",
        "# model.compile(optimizer='adam', loss= call, metrics=[jacard_coef])\n",
        "# model.compile(optimizer='adam', loss=focal_loss, metrics=[jacard_coef])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Drrib_NjEU0",
        "outputId": "19863efe-24cf-4a07-9b30-7e92d1c29f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 240, 240, 4)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 240, 240, 64)         2368      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 240, 240, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 240, 240, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 240, 240, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 240, 240, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 240, 240, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 240, 240, 64)         0         ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 120, 120, 64)         0         ['dropout[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 120, 120, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 120, 120, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 120, 120, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 120, 120, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 120, 120, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 120, 120, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 120, 120, 128)        0         ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 60, 60, 128)          0         ['dropout_1[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 60, 60, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 60, 60, 256)          1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 60, 60, 256)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 60, 60, 256)          590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 60, 60, 256)          1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 60, 60, 256)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 60, 60, 256)          0         ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 256)          0         ['dropout_2[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 30, 30, 512)          2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 30, 30, 512)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 30, 30, 512)          2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 30, 30, 512)          2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 30, 30, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 30, 30, 512)          0         ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 15, 15, 512)          0         ['dropout_3[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 15, 15, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 15, 15, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 15, 15, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 15, 15, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 15, 15, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 15, 15, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 15, 15, 1024)         0         ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 30, 30, 1024)         0         ['dropout_4[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 30, 30, 1536)         0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 30, 30, 512)          7078400   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 30, 30, 512)          2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 30, 30, 512)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 30, 30, 512)          2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 30, 30, 512)          2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 30, 30, 512)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 30, 30, 512)          0         ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 60, 60, 512)          0         ['dropout_5[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 60, 60, 768)          0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 60, 60, 256)          1769728   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 60, 60, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 60, 60, 256)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 60, 60, 256)          590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 60, 60, 256)          1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 60, 60, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 60, 60, 256)          0         ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 120, 120, 256)        0         ['dropout_6[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 120, 120, 384)        0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 120, 120, 128)        442496    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 120, 120, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 120, 120, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 120, 120, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 120, 120, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 120, 120, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 120, 120, 128)        0         ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 240, 240, 128)        0         ['dropout_7[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 240, 240, 192)        0         ['up_sampling2d_3[0][0]',     \n",
            " )                                                                   'dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 240, 240, 64)         110656    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 240, 240, 64)         256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 240, 240, 64)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 240, 240, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 240, 240, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 240, 240, 64)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 240, 240, 64)         0         ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 240, 240, 4)          260       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 240, 240, 4)          16        ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 240, 240, 4)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31403284 (119.79 MB)\n",
            "Trainable params: 31391500 (119.75 MB)\n",
            "Non-trainable params: 11784 (46.03 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"UNet\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 240, 240, 4)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 240, 240, 64)         2368      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 240, 240, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 240, 240, 64)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 240, 240, 64)         36928     ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 240, 240, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 240, 240, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 240, 240, 64)         0         ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 120, 120, 64)         0         ['dropout[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 120, 120, 128)        73856     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 120, 120, 128)        512       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 120, 120, 128)        0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 120, 120, 128)        147584    ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 120, 120, 128)        512       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 120, 120, 128)        0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 120, 120, 128)        0         ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 60, 60, 128)          0         ['dropout_1[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 60, 60, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 60, 60, 256)          1024      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 60, 60, 256)          0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 60, 60, 256)          590080    ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 60, 60, 256)          1024      ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 60, 60, 256)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 60, 60, 256)          0         ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 256)          0         ['dropout_2[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 30, 30, 512)          2048      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 30, 30, 512)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 30, 30, 512)          2359808   ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 30, 30, 512)          2048      ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 30, 30, 512)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 30, 30, 512)          0         ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 15, 15, 512)          0         ['dropout_3[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 15, 15, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 15, 15, 1024)         4096      ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 15, 15, 1024)         0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 15, 15, 1024)         9438208   ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 15, 15, 1024)         4096      ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 15, 15, 1024)         0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 15, 15, 1024)         0         ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 30, 30, 1024)         0         ['dropout_4[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 30, 30, 1536)         0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 30, 30, 512)          7078400   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 30, 30, 512)          2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 30, 30, 512)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 30, 30, 512)          2359808   ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 30, 30, 512)          2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 30, 30, 512)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 30, 30, 512)          0         ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 60, 60, 512)          0         ['dropout_5[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 60, 60, 768)          0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 60, 60, 256)          1769728   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 60, 60, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 60, 60, 256)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 60, 60, 256)          590080    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 60, 60, 256)          1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 60, 60, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 60, 60, 256)          0         ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 120, 120, 256)        0         ['dropout_6[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 120, 120, 384)        0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 120, 120, 128)        442496    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 120, 120, 128)        512       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 120, 120, 128)        0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 120, 120, 128)        147584    ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 120, 120, 128)        512       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 120, 120, 128)        0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 120, 120, 128)        0         ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 240, 240, 128)        0         ['dropout_7[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 240, 240, 192)        0         ['up_sampling2d_3[0][0]',     \n",
            " )                                                                   'dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 240, 240, 64)         110656    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 240, 240, 64)         256       ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 240, 240, 64)         0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 240, 240, 64)         36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 240, 240, 64)         256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 240, 240, 64)         0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 240, 240, 64)         0         ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 240, 240, 4)          260       ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 240, 240, 4)          16        ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 240, 240, 4)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31403284 (119.79 MB)\n",
            "Trainable params: 31391500 (119.75 MB)\n",
            "Non-trainable params: 11784 (46.03 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_img_list)//batch_size\n",
        "val_steps_per_epoch = len(val_img_list)//batch_size"
      ],
      "metadata": {
        "id": "jtMbEkG3qVa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_img_datagen,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    verbose=1,\n",
        "                    epochs=103,\n",
        "                    validation_data=val_img_datagen,\n",
        "                    validation_steps=val_steps_per_epoch,\n",
        "                    shuffle=False,\n",
        "                    callbacks=[cp_callback],)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YywvHDtpjG9z",
        "outputId": "f5792430-7dc1-495d-dafd-ca8e3af65e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7eedd8c65dea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(train_img_datagen,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_img_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iuoWi4lTkPc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in history.history.items():\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "eGELS4ok1g2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['jacard_coef']\n",
        "val_acc = history.history['val_jacard_coef']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOOR87_9kYxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "id": "xNJDNrwwN1J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "metadata": {
        "id": "IYkv2D_5N47t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model instance\n",
        "\n",
        "model = UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.2, batch_norm=True)\n",
        "model.compile(optimizer='adam', loss= FocalLoss(), metrics=[jacard_coef])\n",
        "\n",
        "# Load the previously saved weights\n",
        "model.load_weights(\"/content/drive/MyDrive/models/cp-0051.ckpt\")"
      ],
      "metadata": {
        "id": "XUblHKOOOD2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_img_datagen,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    verbose=1,\n",
        "                    epochs=100,\n",
        "                    validation_data=val_img_datagen,\n",
        "                    validation_steps=val_steps_per_epoch,\n",
        "                    shuffle=False,\n",
        "                    callbacks=[cp_callback],)"
      ],
      "metadata": {
        "id": "JFOGEiJDGXdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on a few images\n",
        "#model = get_model()\n",
        "#model.load_weights('???.hdf5')\n",
        "img, msk = val_img_datagen.__next__()\n",
        "import random\n",
        "test_img_number = random.randint(0, len(img))#6 is good\n",
        "test_img = img[test_img_number]\n",
        "ground_truth=msk[test_img_number]\n",
        "# test_img_norm=test_img[:,:,0][:,:,None]\n",
        "test_img_input=np.expand_dims(test_img, 0)\n",
        "prediction = (model.predict(test_img_input))\n",
        "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
        "print(prediction.shape)\n",
        "print(ground_truth.shape)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray') #only the first channel is displayed\n",
        "\n",
        "plt.subplot(232)\n",
        "plt.title('Original Label')\n",
        "displayed_label = np.argmax(ground_truth, axis=2)\n",
        "plt.imshow(displayed_label, cmap='jet')\n",
        "\n",
        "plt.subplot(233)\n",
        "plt.title('Predicted Label')\n",
        "plt.imshow(predicted_img, cmap='jet')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D6w7tqWZke9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_img_number)"
      ],
      "metadata": {
        "id": "BsYwxbvVjlJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/models/my_model.keras')"
      ],
      "metadata": {
        "id": "sK21FSbuoPNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qth9Izdk385O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}